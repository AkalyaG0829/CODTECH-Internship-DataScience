# CODTECH Internship â€“ Data Science Track  

This repository contains my completed tasks for the CODTECH Data Science Internship.  
Each task demonstrates hands-on skills in **data cleaning, transformation, visualization, machine learning, optimization, and end-to-end deployment**.  

---

## ğŸ“ Task 1 â€“ ETL Pipeline  
- Built a data pipeline to clean and transform **student performance data**.  
- Visualized trends in marks and attendance by department.  
- Focused on **data preprocessing, aggregation, and visualization**.  

**Tools used:** Python, Pandas, Matplotlib, Seaborn  
**ğŸ“‚ Folder:** `Task1_DataPipeline/Task1_ETL/`  

---

## ğŸ“ Task 2 â€“ IMDb Sentiment Analysis (LSTM)  
- Implemented a **Natural Language Processing (NLP)** pipeline using IMDb movie reviews dataset.  
- Trained an **LSTM deep learning model** for sentiment classification (positive/negative).  
- Saved trained model and vectorizer for reproducibility.  
- Produced evaluation metrics and visualizations of model performance.  

**Tools used:** Python, TensorFlow/Keras, NumPy, Pandas, Matplotlib  
**ğŸ“‚ Folder:** `Task2_NLP_Sentiment/`  

---

## ğŸ“ Task 3 â€“ End-to-End Sentiment Analysis Project (Flask UI + API)  
- Designed a **Flask-based Web UI** for real-time sentiment prediction.  
- Integrated trained model and vectorizer into a deployable API.  
- Built a clean, responsive interface (`index.html`, `style.css`) for user interaction.  
- Included dataset (`imdb.csv`), preprocessing scripts, and requirements file for reproducibility.  
- Demonstrated **full-stack deployment skills** with backend + frontend integration.  

**Tools used:** Python, Flask, HTML/CSS, Pandas, Scikit-learn, Git LFS (for large dataset)  
**ğŸ“‚ Folder:** `Task3_EndToEnd_Project/`  

---

## ğŸ“ Task 4 â€“ Production Optimization Model  
- Developed an **optimization model** to minimize production costs while meeting demand and capacity constraints.  
- Utilized **linear programming techniques** to generate optimal production plans.  
- Visualized results with plots (e.g., `production_plan.png`) for clear interpretation.  
- Organized project with modular code (`model.py`, `utils.py`, `visualize.py`) and reproducible notebooks.  

**Tools used:** Python, Pandas, NumPy, Matplotlib, Linear Programming (PuLP/Optimization libraries)  
**ğŸ“‚ Folder:** `Task4_Optimization/`  

---

## ğŸ”§ Technologies Across All Tasks  
- **Programming:** Python, Jupyter Notebook  
- **Libraries:** Pandas, NumPy, Matplotlib, Seaborn, TensorFlow/Keras, Scikit-learn, PuLP  
- **Frameworks:** Flask (for Web UI + API)  
- **Version Control:** Git & GitHub  
- **Data Handling:** Git LFS for large files  

---

## ğŸ‘©â€ğŸ’» Author  
**Akalya G**  
- Pre-final year Computer Science Engineering student  
- Focused on **web developement & data science learner, aspiring data analytics, optimization, and digital credential management**  
